{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca46afe3",
   "metadata": {},
   "source": [
    "#[ë¬¸ì œ]\n",
    "- law_2.docx íŒŒì¼ì„ ì½ê³ , chroma ì €ì¥  \n",
    "- LLMì§ˆë¬¸ -> ë‹µë³€  \n",
    "- ì „ì„¸ì‚¬ê¸°í”¼í•´ì— ê´€í•œ ë²•ë¥  ì§ˆë¬¸ë§Œ ë°›ê¸°.\n",
    "- ì´ ì™¸ì˜ ì§ˆë¬¸ì€ 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732fbaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"ì „ì„¸ì‚¬ê¸°í”¼í•´ì\"ëŠ” ì „ì„¸ì‚¬ê¸°ë¡œ ì¸í•œ í”¼í•´ë¥¼ ì…ì€ ì„ì°¨ì¸ìœ¼ë¡œ, ì œ3ì¡°ì˜ ìš”ê±´ì„ ëª¨ë‘ ê°–ì¶˜ í›„ ì „ì„¸ì‚¬ê¸°í”¼í•´ì§€ì›ìœ„ì›íšŒì˜ ì‹¬ì˜ ë° ì˜ê²°ì„ ê±°ì³ êµ­í† êµí†µë¶€ì¥ê´€ì´ ê²°ì •í•œ ì„ì°¨ì¸ì„ ë§í•©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "\n",
    "## 1. ë¬¸ì„œ ë‚´ìš© ì½ê³  ë¶„í• \n",
    "loader = Docx2txtLoader('law_2.docx') #ì¸ìŠ¤í„´ìŠ¤ ìƒì„± #ë¬¸ì„œ í™•ì¸\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(  #ë¶„í• ì„ í•˜ê¸°ìœ„í•œ ì„¤ì •\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ") #ë‚˜ì¤‘ì— ì—¬ëŸ¬ë²ˆì˜ ì§ˆë¬¸ì„ í†µí•´ ì •í™•ë„ë¥¼ í™•ì¸\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter) #íŒŒì¼ì„ ê°–ê³  íŒŒë¼ë¯¸í„°ì— ì„¤ì •ëœ ì½ê³  ë¶„í• \n",
    "\n",
    "## 2. ì„ë² ë”© -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ \n",
    "## 2.1. í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸°\n",
    "load_dotenv() #ì˜ ì½ì–´ì™”ë‹¤ëŠ” True\n",
    "\n",
    "## 2.2. ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large') #ì„±ëŠ¥ ì¢‹ì€ ìœ ë£Œ  # ìœ„ì—ì„œ OPENAI_API_KEY ì½ì—ˆê¸° ë•Œë¬¸ì— \n",
    "\n",
    "# # ## 2.3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ########í•œë²ˆ ì‹¤í–‰í–ˆê¸° ë•Œë¬¸ì—\n",
    "##[ë°©ë²• 1] in memory\n",
    "# database = Chroma.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "#     persist_directory='./chroma',\n",
    "#     collection_name='chroma-law',\n",
    "# )\n",
    "\n",
    "## ë¡œì»¬ì— ì €ì¥ëœ ì„ë² ë”© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°\n",
    "\n",
    "database =Chroma(\n",
    "    collection_name='chroma-law',\n",
    "    persist_directory='./chroma',\n",
    "    embedding_function=embedding,\n",
    ")\n",
    "\n",
    "\n",
    "## 3. ì§ˆë¬¸ì´ ìˆìœ¼ë©´, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(vector_store)ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "\n",
    "## 3.1. ì‚¬ìš©ì ì§ˆë¬¸\n",
    "# query = 'ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ”?'\n",
    "query = 'ì „ì„¸ì‚¬ê¸° í”¼í•´ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”? '\n",
    "\n",
    "## 3.2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ (ì ìˆ˜ í¬í•¨)\n",
    "retrieved_docs = database.similarity_search(query=query, k=2)\n",
    "\n",
    "## ë¬¸ì„œ ê°ì²´ì—ì„œ ë¬¸ìì—´ë§Œ ì¶”ì¶œ\n",
    "\n",
    "\n",
    "\n",
    "## 3.3 ë¬¸ì„œ ê°ì²´ -> í•˜ë‚˜ì˜ ë¬¸ìì—´\n",
    "## ë¦¬ìŠ¤íŠ¸ for ë¬¸\n",
    "context = 'ğŸ¤·â€â™€ï¸ğŸ¤·â€â™€ï¸\\n\\n'.join([doc.page_content for doc in retrieved_docs])\n",
    "context\n",
    "\n",
    "\n",
    "## 4.0 ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë¬¸ì„œë¥¼ LLMì— ì§ˆë¬¸ê³¼ ê°™ì´ ì „ë‹¬ \n",
    "\n",
    "## 4.1. í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "prompt = '''\n",
    "[identity]\n",
    "- ë‹¹ì‹ ì€ ì „ì„¸ì‚¬ê¸° í”¼í•´ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "- [context]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "- ì „ì„¸ì‚¬ê¸° í”¼í•´ ë²•ë¥  ì´ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {query}\n",
    "'''\n",
    "\n",
    "## 4.2. í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ì— ê°’ ì„¤ì •\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs=context,\n",
    "    query=query,\n",
    ")\n",
    "\n",
    "## 4.3. LLM ëª¨ë¸ ìƒì„±(chatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)  \n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "## 4.4. LLM ëª¨ë¸ì— ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë³´ëƒ„  \n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "ai_message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
