{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ebb970",
   "metadata": {},
   "source": [
    "## íŒŒì¸ì½˜ ë²¡í„° DB ì €ì¥\n",
    "**A**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ca3b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732fbaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ê°€ê²©ì€ ì œ3ì¡°ì— ì œì‹œëœ ì‚°ì • ê¸°ì¤€ì— ë”°ë¼, ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ì„ëŒ€ì¸ì´ ì†Œìœ í•œ ëª¨ë“  ì£¼íƒì˜ ê°€ê²© í•©ê³„ì•¡ ì¤‘ ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ê°€ê²©ì´ í¬í•¨ëœ ë¹„ìœ¨ë¡œ ì•ˆë¶„í•˜ì—¬ ê³„ì‚°ë©ë‹ˆë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê°€ëª©ì˜ ê³„ì‚°ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì‚°ì •ë©ë‹ˆë‹¤:\\n\\n\\\\[ A \\\\times \\\\left(\\\\frac{B}{C}\\\\right) \\\\]\\n\\nì—¬ê¸°ì„œ:\\n- \\\\( A \\\\)ëŠ” ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ì„ëŒ€ì¸ì´ ì²´ë‚©í•œ ê³ ì§€ ë˜ëŠ” ì‹ ê³  ê±´ë³„ êµ­ì„¸ ê¸ˆì•¡ì…ë‹ˆë‹¤.\\n- \\\\( B \\\\)ëŠ” ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ê°€ê²©ì…ë‹ˆë‹¤.\\n- \\\\( C \\\\)ëŠ” ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ì„ëŒ€ì¸ì´ ë³´ìœ í•œ ëª¨ë“  ì£¼íƒì˜ ê°€ê²© í•©ê³„ì•¡ì…ë‹ˆë‹¤.\\n\\nì´ë¥¼ í†µí•´ ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ê°€ê²©ì€ ì„ëŒ€ì¸ì˜ ì „ì²´ ì£¼íƒ ë³´ìœ  ìƒí™©ê³¼ êµ­ì„¸ ì²´ë‚© ìƒí™©ì— ë”°ë¼ì„œ ë¹„ë¡€ì ìœ¼ë¡œ ì±…ì •ë©ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter \n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "## 1. ë¬¸ì„œ ë‚´ìš© ì½ê³  ë¶„í• \n",
    "loader = Docx2txtLoader('law_2.docx') #ì¸ìŠ¤í„´ìŠ¤ ìƒì„± #ë¬¸ì„œ í™•ì¸\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(  #ë¶„í• ì„ í•˜ê¸°ìœ„í•œ ì„¤ì •\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ") #ë‚˜ì¤‘ì— ì—¬ëŸ¬ë²ˆì˜ ì§ˆë¬¸ì„ í†µí•´ ì •í™•ë„ë¥¼ í™•ì¸\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter) #íŒŒì¼ì„ ê°–ê³  íŒŒë¼ë¯¸í„°ì— ì„¤ì •ëœ ì½ê³  ë¶„í• \n",
    "\n",
    "## 2. ì„ë² ë”© -> ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ \n",
    "## 2.1. í™˜ê²½ë³€ìˆ˜ ì½ì–´ì˜¤ê¸°\n",
    "load_dotenv() #ì˜ ì½ì–´ì™”ë‹¤ëŠ” True\n",
    "\n",
    "## 2.2. ì„ë² ë”© ëª¨ë¸ ì§€ì •\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large') #ì„±ëŠ¥ ì¢‹ì€ ìœ ë£Œ  # ìœ„ì—ì„œ OPENAI_API_KEY ì½ì—ˆê¸° ë•Œë¬¸ì— \n",
    "\n",
    "\n",
    "# # ## 2.3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ########í•œë²ˆ ì‹¤í–‰í–ˆê¸° ë•Œë¬¸ì—\n",
    "## íŒŒì´ì½˜ì— ë²¡í„° í˜•íƒœë¡œ ì €ì¥\n",
    "# database = PineconeVectorStore.from_documents(\n",
    "#     documents=document_list,\n",
    "#     embedding=embedding,\n",
    "#     index_name='law-2',\n",
    "# )\n",
    "\n",
    "## pinecone: server\n",
    "api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "#íŒŒì´ì½˜ì— ì €ì¥ë˜ì–´ìˆëŠ” ì¸ë±ìŠ¤ ì½ì–´ì˜¤ê¸°\n",
    "database = PineconeVectorStore(\n",
    "    index=pc.Index('law-2'),\n",
    "    embedding=embedding,\n",
    ")\n",
    "\n",
    "## 3. ì§ˆë¬¸ì´ ìˆìœ¼ë©´, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤(vector_store)ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "\n",
    "## 3.1. ì‚¬ìš©ì ì§ˆë¬¸\n",
    "# query = 'ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ëŠ”?'\n",
    "# query = 'ì „ì„¸ì‚¬ê¸° í”¼í•´ìëŠ” ëˆ„êµ¬ì¸ê°€ìš”? '\n",
    "# query = 'ì „ì„¸ì‚¬ê¸° í”¼í•´ì£¼íƒ ì„ëŒ€ì¸ì˜ êµ­ì„¸ ê³„ì‚°ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?'\n",
    "query = 'ì „ì„¸ì‚¬ê¸° í”¼í•´ ì£¼íƒì˜ ê°€ê²©ì€?'\n",
    "\n",
    "## 3.2. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ (ì ìˆ˜ í¬í•¨)\n",
    "retrieved_docs = database.similarity_search(query=query, k=2)\n",
    "\n",
    "## 3.3 ë¬¸ì„œ ê°ì²´ -> í•˜ë‚˜ì˜ ë¬¸ìì—´\n",
    "## ë¦¬ìŠ¤íŠ¸ for ë¬¸\n",
    "context = 'ğŸ¤·â€â™€ï¸ğŸ¤·â€â™€ï¸\\n\\n'.join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "\n",
    "\n",
    "## 4.0 ìœ ì‚¬ë„ ê²€ìƒ‰ìœ¼ë¡œ ê°€ì ¸ì˜¨ ë¬¸ì„œë¥¼ LLMì— ì§ˆë¬¸ê³¼ ê°™ì´ ì „ë‹¬ \n",
    "\n",
    "## 4.1. í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "prompt = '''\n",
    "[identity]\n",
    "- ë‹¹ì‹ ì€ ì „ì„¸ì‚¬ê¸° í”¼í•´ ë²•ë¥  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "- [context]ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "- ì „ì„¸ì‚¬ê¸° í”¼í•´ ë²•ë¥  ì´ì™¸ì˜ ì§ˆë¬¸ì—ëŠ” 'ë‹µë³€ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¡œ ë‹µí•˜ì„¸ìš”.\n",
    "\n",
    "[context]\n",
    "{retrieved_docs}\n",
    "\n",
    "Question: {query}\n",
    "'''\n",
    "\n",
    "## 4.2. í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ì— ê°’ ì„¤ì •\n",
    "formatted_prompt = prompt.format(\n",
    "    retrieved_docs=context,\n",
    "    query=query,\n",
    ")\n",
    "\n",
    "## 4.3. LLM ëª¨ë¸ ìƒì„±(chatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„±)  \n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "## 4.4. LLM ëª¨ë¸ì— ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë³´ëƒ„  \n",
    "ai_message = llm.invoke(formatted_prompt)\n",
    "ai_message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
